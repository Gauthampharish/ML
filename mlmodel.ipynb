{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac4517e-51fb-4333-890e-8a4f7c91da10",
   "metadata": {},
   "source": [
    "READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613689e-8531-4b0c-9a7c-36d7e4e8300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read from a text file\n",
    "text_file_path = 'data.txt'\n",
    "text_data = pd.read_csv(text_file_path, sep='\\t', header=None)\n",
    "print(\"Text file data:\")\n",
    "print(text_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2ae5b1-ec69-4ccb-8698-72e322a449de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read from a CSV file\n",
    "csv_file_path = 'data.csv'\n",
    "csv_data = pd.read_csv(csv_file_path)\n",
    "print(\"\\nCSV file data:\")\n",
    "print(csv_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0df46b-c1ff-42ab-b772-2a358363ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read from an Excel file\n",
    "excel_file_path = 'data.xlsx'\n",
    "excel_data = pd.read_excel(excel_file_path)\n",
    "print(\"\\nExcel file data:\")\n",
    "print(excel_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6896a-debc-43ba-af5d-676b5d4075b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read from a specific sheet in an Excel file\n",
    "excel_file_path = 'data.xlsx'\n",
    "sheet_name = 'Sheet1'  # Specify the sheet name or index (0-indexed)\n",
    "excel_sheet_data = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "print(\"\\nData from sheet '{}' in Excel file:\".format(sheet_name))\n",
    "print(excel_sheet_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040dd13-3697-4980-b182-17a3dedf1679",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e2c62-2ecf-47e6-9c27-fd51f43e43de",
   "metadata": {},
   "source": [
    "missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77168e2e-6e7c-4a50-971d-7e0b2610b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame with missing values\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 2, 3, None, 5],\n",
    "        'C': [1, 2, 3, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_dropna = df.dropna()\n",
    "\n",
    "# Fill missing values with a specific value\n",
    "df_fillna = df.fillna(value=0)\n",
    "\n",
    "print(\"DataFrame after dropping rows with missing values:\")\n",
    "print(df_dropna)\n",
    "print(\"\\nDataFrame after filling missing values with 0:\")\n",
    "print(df_fillna)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798f784-88ff-48de-b029-581e533889e5",
   "metadata": {},
   "source": [
    "Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b95d453-65c6-4873-a93e-449cdb585c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with missing values\n",
    "df_drop_columns = df.dropna(axis=1)\n",
    "\n",
    "print(\"\\nDataFrame after dropping columns with missing values:\")\n",
    "print(df_drop_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b4e70-86d3-4ba5-ab2f-bb64384636cc",
   "metadata": {},
   "source": [
    "Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca18970-5fdc-4df6-abd6-282871b245f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical column to dummy variables\n",
    "df_categorical = pd.get_dummies(df, columns=['C'])\n",
    "\n",
    "print(\"\\nDataFrame after converting categorical column to dummy variables:\")\n",
    "print(df_categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d282a-eced-4471-a170-ad0d1e1d2b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec408c5-12ca-4d91-986a-3877a9b768c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Perform feature selection\n",
    "X = df_fillna.drop('C', axis=1)\n",
    "y = df_fillna['C']\n",
    "selector = SelectKBest(score_func=f_regression, k=1)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "print(\"\\nSelected features after feature selection:\")\n",
    "print(X_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa9323-a5aa-4562-a0e7-a8f2129df5b6",
   "metadata": {},
   "source": [
    "normalizatoion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d57a3-3559-4ef3-ac1b-32211378cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalize numerical data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_new)\n",
    "\n",
    "print(\"\\nNormalized data:\")\n",
    "print(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb3509-4f69-4b41-906f-39ebba04a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature by adding two existing features\n",
    "df_fillna['D'] = df_fillna['A'] + df_fillna['B']\n",
    "\n",
    "print(\"\\nDataFrame after adding a new feature:\")\n",
    "print(df_fillna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae9016a-12ca-4f90-a6b6-e9910366a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale the new feature\n",
    "scaler = MinMaxScaler()\n",
    "df_fillna['D_scaled'] = scaler.fit_transform(df_fillna[['D']])\n",
    "\n",
    "print(\"\\nDataFrame after scaling the new feature:\")\n",
    "print(df_fillna)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a83d8f-e420-4fdf-b2b1-44ea525ec4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'A': [1, 2, 3, 4, 5],\n",
    "        'B': [6, 7, 8, 9, 10],\n",
    "        'C': [11, 12, 13, 14, 15],\n",
    "        'D': [16, 17, 18, 19, 20],\n",
    "        'E': [21, 22, 23, 24, 25],\n",
    "        'F': [26, 27, 28, 29, 30]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split columns into first 5 and last 2 columns\n",
    "first_5_columns = df.iloc[:, :5]\n",
    "last_2_columns = df.iloc[:, -2:]\n",
    "\n",
    "print(\"First 5 columns:\")\n",
    "print(first_5_columns)\n",
    "\n",
    "print(\"\\nLast 2 columns:\")\n",
    "print(last_2_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16825ff-299f-4758-9257-fbad2fc651cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#feature selction - regression\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'A': [1, 2, 3, 4, 5],\n",
    "        'B': [6, 7, 8, 9, 10],\n",
    "        'C': [11, 12, 13, 14, 15],\n",
    "        'D': [16, 17, 18, 19, 20],\n",
    "        'E': [21, 22, 23, 24, 25],\n",
    "        'F': [26, 27, 28, 29, 30]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop('F', axis=1)  # Features\n",
    "y = df['F']  # Target variable\n",
    "\n",
    "# Perform feature selection using SelectKBest with f_regression\n",
    "selector = SelectKBest(score_func=f_regression, k=3)  # Select top 3 features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = X.columns[selected_indices]\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd17db7c-5dc2-4eea-ae16-65108da033e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selction classfication\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load sample iris dataset\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# Perform feature selection using SelectKBest with chi-squared test\n",
    "selector = SelectKBest(score_func=chi2, k=2)  # Select top 2 features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = X.columns[selected_indices]\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ebee8-1dbf-4bf0-941c-25408d73d0ad",
   "metadata": {},
   "source": [
    "eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1978022-a09e-46f7-ab68-580790b66fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67056b43-2112-4f56-9257-f2710eb9c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of columns\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bad1fb-6d04-4c5b-bee3-13b337b73422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics of the dataset\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6919b903-e8ee-42fa-b875-02bed591fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea99ac-014c-4642-b960-a7f725d62a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histograms for numerical columns\n",
    "df.hist(figsize=(12, 8))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f74784-39e0-4e34-87eb-d1870c47624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplots for numerical columns\n",
    "df.boxplot(figsize=(12, 8))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f3e29a-a041-4434-b1b0-2d60549e681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d5b36e-f7b5-4444-af90-73e91bc7a88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot between two numerical columns\n",
    "plt.scatter(df['column1'], df['column2'])\n",
    "plt.xlabel('column1')\n",
    "plt.ylabel('column2')\n",
    "plt.title('Scatter Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ecb457-63cc-48d0-8885-10837f34d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect outliers using Z-score\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "z_scores = np.abs(stats.zscore(df.select_dtypes(include=['number'])))\n",
    "outliers = (z_scores > 3).all(axis=1)\n",
    "\n",
    "# Print indices of outliers\n",
    "print(df.index[outliers])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aee576-fa4a-46a8-969b-003a6d9b95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "df_encoded = pd.get_dummies(df, columns=['categorical_column'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f86bf1-9c43-4f9c-8d98-69992716b53a",
   "metadata": {},
   "source": [
    "**dimension**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911bca6c-96f5-41ee-9446-05c71a361340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Plot the PCA-transformed data\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA of IRIS dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82439592-d273-4431-9f73-9cb88fd5d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=0)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# Plot the t-SNE-transformed data\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='viridis')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.title('t-SNE of IRIS dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7c1f2-8c72-4f26-a15a-a42bae9c3057",
   "metadata": {},
   "source": [
    "**MODELS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d8581-a75d-4212-8046-94920d1c18e1",
   "metadata": {},
   "source": [
    "**regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd67767-5a4a-48a2-b898-2de58b4a506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821eefe8-b1fc-44d1-ac30-d1d4a2cacafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Fit the Ridge regression model\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "print(\"Ridge Mean Squared Error:\", mse_ridge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071318c-d887-4388-9d17-315ab4656602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Fit the Lasso regression model\n",
    "lasso = Lasso(alpha=1.0)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "print(\"Lasso Mean Squared Error:\", mse_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c30dba-77ce-406e-8a94-afadd7c0445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Fit the ElasticNet regression model\n",
    "elasticnet = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "elasticnet.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_elasticnet = elasticnet.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_elasticnet = mean_squared_error(y_test, y_pred_elasticnet)\n",
    "print(\"ElasticNet Mean Squared Error:\", mse_elasticnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e4a54a-d2f6-4a28-b353-e788f4f49737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "best_features = None\n",
    "best_score = -np.inf\n",
    "\n",
    "for k in range(1, len(X.columns)+1):\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_selected = selector.fit_transform(X_train, y_train)\n",
    "    scores = cross_val_score(LinearRegression(), X_selected, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    if scores.mean() > best_score:\n",
    "        best_score = scores.mean()\n",
    "        best_features = X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "print(\"Best features:\", best_features)\n",
    "print(\"Best score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9782d542-3f7a-40c4-856b-eef1ea9d6fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78292a22-994a-4405-98eb-c8018adecb63",
   "metadata": {},
   "source": [
    "classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76858b8e-9821-4f9a-b920-4539e84e6404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec62d6b-a94d-481f-a462-fc4e61d2a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e4431-689e-422c-90af-3528704522bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa8774-ed52-4cab-b0cd-ed708092ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are already defined\n",
    "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"CART with Gini Impurity Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cabc17-9f38-476e-b33c-d5ff2dfd65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", accuracy_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff4316-efe1-4d39-9965-df25bf6d1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47552a47-d143-40af-a81f-283c1ebb61d2",
   "metadata": {},
   "source": [
    "clusterring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d320c-3a5f-4ad3-b079-8c06942b9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assuming X is your data\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ebd742-2b76-440b-b523-ba977b2b08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=3)\n",
    "labels_agg = agg_clustering.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df09006-33a0-4b53-a738-0354b7c76226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "labels_dbscan = dbscan.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64648ace-26df-4f2e-98de-0a98802d691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "mean_shift = MeanShift()\n",
    "labels_ms = mean_shift.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af3ee8e-192d-4c27-b1a7-63227dbf8e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "labels_gmm = gmm.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534de164-e051-4716-8578-f17793c5ca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "spectral = SpectralClustering(n_clusters=3, assign_labels='discretize', random_state=42)\n",
    "labels_spectral = spectral.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c603f0ac-bbfc-4b90-9f2d-f8a7caefd0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample data\n",
    "X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)\n",
    "\n",
    "# Fit KMeans clustering model\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Visualize clusters\n",
    "plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_, cmap='viridis')\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8aa9ae-9255-49d1-b076-c7fd1c2699f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create and train the Perceptron model\n",
    "clf = Perceptron()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Perceptron Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a481e9a-dd04-48dc-8042-bdf5d782693c",
   "metadata": {},
   "source": [
    "ensemblling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03617d9b-278d-400f-a72c-1fe9e1e6f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870494a3-d7c7-4077-ae8c-1dec66ac80c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf24f11-c890-45b2-89da-a6c1f36ed737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "gb = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e91b927-b94f-47ba-9b2f-be902fa0f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6ae1b-51c6-4d49-8cb3-ec2d5533e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the base classifiers\n",
    "clf1 = LogisticRegression(random_state=42)\n",
    "clf2 = DecisionTreeClassifier(random_state=42)\n",
    "clf3 = SVC(random_state=42)\n",
    "\n",
    "# Create a Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[('lr', clf1), ('dt', clf2), ('svc', clf3)], voting='hard')\n",
    "\n",
    "# Fit the Voting Classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Voting Classifier Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ad929-c07a-4590-b24b-fb7b485887ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create a synthetic dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the base regressors\n",
    "reg1 = LinearRegression()\n",
    "reg2 = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Create a Voting Regressor\n",
    "voting_reg = VotingRegressor(estimators=[('lr', reg1), ('dt', reg2)])\n",
    "\n",
    "# Fit the Voting Regressor\n",
    "voting_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = voting_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Voting Regressor Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9852637-7e1c-418b-8868-1b67d4797e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, silhouette_score, davies_bouldin_score, calinski_harabasz_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Regression example\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}, MSE: {mse}, RMSE: {rmse}, R-squared: {r2}\")\n",
    "\n",
    "# Clustering example\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "\n",
    "silhouette = silhouette_score(X, y_pred)\n",
    "davies_bouldin = davies_bouldin_score(X, y_pred)\n",
    "calinski_harabasz = calinski_harabasz_score(X, y_pred)\n",
    "\n",
    "print(f\"Silhouette Score: {silhouette}, Davies-Bouldin Index: {davies_bouldin}, Calinski-Harabasz Index: {calinski_harabasz}\")\n",
    "\n",
    "# Classification example\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dummy classifier for illustration purposes\n",
    "from sklearn.dummy import DummyClassifier\n",
    "classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "\n",
    "# Plotting\n",
    "# For regression\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "# For clustering (2D data assumed)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Clustering Result')\n",
    "plt.show()\n",
    "\n",
    "# For classification (2D data assumed)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Actual Classes')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
