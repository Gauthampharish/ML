{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98518d75",
   "metadata": {},
   "source": [
    "## INTRO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6881c0c5",
   "metadata": {},
   "source": [
    "### IMPORTING LIBRARIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5f30d9",
   "metadata": {},
   "source": [
    "### READING DATASET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b412c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv = pd.read_csv(\"./FuelConsumption.csv\")\n",
    "data_excel = pd.read_excel(\"your_excel_file.xlsx\")\n",
    "data_text = pd.read_csv(\"your_text_file.txt\", delimiter='\\t') #if delimiter in text is comma change delimiter alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read from a specific sheet in an Excel file\n",
    "excel_file_path = 'data.xlsx'\n",
    "sheet_name = 'Sheet1'  # Specify the sheet name or index (0-indexed)\n",
    "excel_sheet_data = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "print(\"\\nData from sheet '{}' in Excel file:\".format(sheet_name))\n",
    "print(excel_sheet_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c10db",
   "metadata": {},
   "source": [
    "### ANALYZING DATASET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a11fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "data.head()\n",
    "data.tail()\n",
    "data.shape\n",
    "data['age'].dtype\n",
    "data['age'].max() data['age'].argmax() #(Similarly for Min) max->val argmax->pos\n",
    "data.describe()\n",
    "data['age'].mean() #median() mode()\n",
    "data.columns\n",
    "data.rename(columns={'sex':'gender'},inplace=True)\n",
    "data1['age'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ad36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()\n",
    "data.isnull().sum()\n",
    "data.groupby('age').mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861bca8",
   "metadata": {},
   "source": [
    "### SELECTION and DROPPING METHODS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6f10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['age'] > 39.0]\n",
    "data[['age','sex','bmi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1]\n",
    "data.iloc[3]\n",
    "data.iloc[0:2,4:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459fa1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('bmiAgeSum',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94148345",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna()\n",
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023d3e90",
   "metadata": {},
   "source": [
    "### GRAPHS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8d2f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr()\n",
    "# Create a heatmap with correlation values\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5fdc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff708f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data1, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['Cement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 2)) \n",
    "sns.boxplot(data=data1)\n",
    "plt.title('Box Plots for Each Column')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9b97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease_distribution = df['heart_disease'].value_counts()\n",
    "labels = {0: 'No Heart Disease', 1: 'Heart Disease'}\n",
    "heart_disease_distribution.index = heart_disease_distribution.index.map(labels)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(heart_disease_distribution, labels=heart_disease_distribution.index, autopct='%1.1f%%', startangle=90, colors=['lightcoral', 'lightgreen'])\n",
    "plt.title('Distribution of Heart Disease')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = [15, 5])\n",
    "sns.countplot(y='sex', data=df, palette=\"pastel\")\n",
    "plt.xlabel('Gender (0 = Female, 1 = Male)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56224fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab = pd.crosstab(data['dept'], data['salary'])\n",
    "cross_tab.plot(kind='bar', stacked=True, colormap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d700424",
   "metadata": {},
   "source": [
    "### OUTLINERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7aadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 3 #beyond 3 Std Deviation\n",
    "\n",
    "for column_name in data.columns[:-1]:\n",
    "    median_value = data[column_name].median()\n",
    "    z_scores = np.abs((data[column_name] - data[column_name].median()) / data[column_name].std())\n",
    "    outliers = z_scores > threshold\n",
    "    data.loc[outliers, column_name] = median_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a124ad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_filtered = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    return df_filtered\n",
    "columns_to_remove_outliers = ['age', 'resting_blood_pressure', 'cholesterol_level', 'max_heart_rate', 'exercise_induced_depression']\n",
    "for column in columns_to_remove_outliers:\n",
    "    data = remove_outliers(data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f8566",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#feature selction - regression\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'A': [1, 2, 3, 4, 5],\n",
    "        'B': [6, 7, 8, 9, 10],\n",
    "        'C': [11, 12, 13, 14, 15],\n",
    "        'D': [16, 17, 18, 19, 20],\n",
    "        'E': [21, 22, 23, 24, 25],\n",
    "        'F': [26, 27, 28, 29, 30]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop('F', axis=1)  # Features\n",
    "y = df['F']  # Target variable\n",
    "\n",
    "# Perform feature selection using SelectKBest with f_regression\n",
    "selector = SelectKBest(score_func=f_regression, k=3)  # Select top 3 features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = X.columns[selected_indices]\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0689a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selction classfication\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load sample iris dataset\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# Perform feature selection using SelectKBest with chi-squared test\n",
    "selector = SelectKBest(score_func=chi2, k=2)  # Select top 2 features\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = X.columns[selected_indices]\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538dd398",
   "metadata": {},
   "source": [
    "### ENCODERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder1 = LabelEncoder()\n",
    "data1['MAKE'] = label_encoder1.fit_transform(data1['MAKE'])+1  #IF Probaility classifer do +1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d092892",
   "metadata": {},
   "source": [
    "### TRAIN-TEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.iloc[:, :-1]\n",
    "Y= data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e712081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, Y1, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d6704a",
   "metadata": {},
   "source": [
    "### SCALERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73390ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler , StandardScaler\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler1 = StandardScaler()\n",
    "X_train2=scaler1.fit_transform(X_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d7275",
   "metadata": {},
   "source": [
    "## MODELS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659db1e6",
   "metadata": {},
   "source": [
    "#### LINEAR and MULTIPLE REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7582f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model1=LinearRegression()\n",
    "model1.fit(X_train1,y_train1)\n",
    "\n",
    "intercept=model1.intercept_\n",
    "coeff_df1 = pd.DataFrame(model1.coef_,X1.columns,columns=['Coefficient'])\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf25da3",
   "metadata": {},
   "source": [
    "#### NAIVE BAYES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model=GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ddb0d",
   "metadata": {},
   "source": [
    "#### DECISION TREE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_entropy=DecisionTreeClassifier(criterion='entropy',max_depth=3)  #ENTROPY / GINI\n",
    "model_entropy.fit(x_train,y_train)\n",
    "pred=model_entropy.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e6ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(model_entropy)\n",
    "fig=plt.figure(figsize=(4,4),dpi=300)\n",
    "fn=['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width', 'Species']\n",
    "cn=['setosa', 'versicolor', 'virginica']\n",
    "tree.plot_tree(model_entropy,feature_names=fn,class_names=cn,filled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be88972",
   "metadata": {},
   "source": [
    "#### DECISION TREE REGRESSOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5cac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model=DecisionTreeRegressor(max_depth=4)\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "tree.plot_tree(model, fontsize=10, filled=True, rounded=True,\n",
    "               feature_names=list(data.columns)[:-1],\n",
    "               class_names=['satisfaction_level'])\n",
    "\n",
    "plt.title(\"Decision Tree Regressor\", size=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac9e979",
   "metadata": {},
   "source": [
    "#### KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=3,metric=\"euclidean\")\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "k_vals = [i for i in range(1,100)]\n",
    "features = [\"norm_balance\",\"norm_income\"]\n",
    "target = \"defaulter\"\n",
    "for k in k_vals:\n",
    "    model = KNeighborsClassifier(n_neighbors=k,metric='euclidean')\n",
    "    model.fit(X_train,Y_train)\n",
    "    train_accuracy_k = model.score(X_train,Y_train)\n",
    "    test_accuracy_k = model.score(X_test,Y_test)\n",
    "    train_accuracies.append(train_accuracy_k)\n",
    "    test_accuracies.append(test_accuracy_k)\n",
    "plt.plot(k_vals,train_accuracies)\n",
    "plt.plot(k_vals,test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30f11b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_n = defaulter.loc[0,[\"norm_balance\",\"norm_income\"]]\n",
    "x2_n = defaulter.loc[1,[\"norm_balance\",\"norm_income\"]]\n",
    "np.linalg.norm(x1_n-x2_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397dcf2",
   "metadata": {},
   "source": [
    "#### PERCEPTRON : SINGLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8761f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "#CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss_curve_)\n",
    "plt.title(\"Loss Curve\", fontsize=14)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd62d303",
   "metadata": {},
   "source": [
    "#### PERCEPTRON : MULTI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e473b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(150,100,50),\n",
    "                        max_iter = 300,activation = 'relu',\n",
    "                        solver = 'adam')\n",
    "model.fit(trainX_scaled, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6016d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.loss_curve_)\n",
    "plt.title(\"Loss Curve\", fontsize=14)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2457d769",
   "metadata": {},
   "source": [
    "#### SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b49a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC() \n",
    "svc.fit(X_train,y_train)\n",
    "y_pred=svc.predict(X_test)\n",
    "print('Accuracy Score:')\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e146293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'rbf', 'poly']\n",
    "results = {'Model Number': [], 'Kernel Name': [], 'Chosen Parameters': [],\n",
    "           'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-score': []}\n",
    "\n",
    "for i, kernel in enumerate(kernels):\n",
    "    \n",
    "    model = SVC(kernel=kernel)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    results['Model Number'].append(i+1)\n",
    "    results['Kernel Name'].append(kernel)\n",
    "    results['Chosen Parameters'].append(model.get_params())\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Precision'].append(precision)\n",
    "    results['Recall'].append(recall)\n",
    "    results['F1-score'].append(f1)\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f38cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(data=results_df, x='Kernel Name', y='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d897c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# AUC Value\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(['AUC'], [roc_auc], color='darkorange')\n",
    "plt.ylabel('AUC Value')\n",
    "plt.title('Area Under Curve (AUC)')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3470325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define different values of k for k-fold cross-validation\n",
    "k_values = [5, 10]\n",
    "\n",
    "# Results dictionary\n",
    "results_kfold_cv = {'Model Number': [], 'Kernel Name': [],\n",
    "                    'Mean Accuracy': [], 'Mean Precision': [], 'Mean Recall': [], 'Mean F1-score': []}\n",
    "\n",
    "for k in k_values:\n",
    "    for i, kernel in enumerate(kernels):\n",
    "        model = SVC(kernel=kernel)\n",
    "        mean_accuracy = np.mean(cross_val_score(model, X_train, y_train, cv=k, scoring='accuracy'))\n",
    "        mean_precision = np.mean(cross_val_score(model, X_train, y_train, cv=k, scoring='precision_weighted'))\n",
    "        mean_recall = np.mean(cross_val_score(model, X_train, y_train, cv=k, scoring='recall_weighted'))\n",
    "        mean_f1_score = np.mean(cross_val_score(model, X_train, y_train, cv=k, scoring='f1_weighted'))\n",
    "\n",
    "        results_kfold_cv['Model Number'].append(i + 1)\n",
    "        results_kfold_cv['Kernel Name'].append(kernel)\n",
    "        results_kfold_cv['Mean Accuracy'].append(mean_accuracy)\n",
    "        results_kfold_cv['Mean Precision'].append(mean_precision)\n",
    "        results_kfold_cv['Mean Recall'].append(mean_recall)\n",
    "        results_kfold_cv['Mean F1-score'].append(mean_f1_score)\n",
    "\n",
    "# Display results\n",
    "results_kfold_cv_df = pd.DataFrame(results_kfold_cv)\n",
    "print(\"K-Fold Cross-Validation Results:\")\n",
    "print(results_kfold_cv_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b3501",
   "metadata": {},
   "source": [
    "#### ENSEMBLING METHODS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da439d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=101)\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf1053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('random_forest', random_forest),\n",
    "    ('svm_classifier', svm_classifier),\n",
    "    ('logistic_regression', logistic_model)\n",
    "], voting='hard')\n",
    "\n",
    "# Fit Voting Classifier\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions with the voting classifier\n",
    "voting_predictions = voting_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of the voting classifier\n",
    "voting_accuracy = accuracy_score(y_test, voting_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd3294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Initialize AdaBoost\n",
    "model_adaboost = AdaBoostClassifier()\n",
    "\n",
    "# Fit AdaBoost model\n",
    "model_adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds_adaboost = model_adaboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "model_xgb = xgb.XGBClassifier()\n",
    "\n",
    "# Fit XGBoost model\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "preds_xgb = model_xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aae9d6",
   "metadata": {},
   "source": [
    "#### CLUSTERING MODELS : K MODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edadb8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kmodes import KModes\n",
    "K-modes Clustering\n",
    "km_cao = KModes(n_clusters=2, init = \"Cao\", n_init = 1, verbose=1) #Cao, Huang (defualt), random , matching\n",
    "fitClusters_cao = km_cao.fit_predict(bank_cust)\n",
    "clusterCentroidsDf = pd.DataFrame(km_cao.cluster_centroids_)\n",
    "\n",
    "cost = []\n",
    "for num_clusters in list(range(1,5)):\n",
    "    kmode = KModes(n_clusters=num_clusters, init = \"Cao\", n_init = 1, verbose=1)\n",
    "    kmode.fit_predict(bank_cust)\n",
    "    cost.append(kmode.cost_)\n",
    "\n",
    "bank_cust = bank_cust_copy.reset_index()  \n",
    "clustersDf = pd.DataFrame(fitClusters_cao)\n",
    "clustersDf.columns = ['cluster_predicted']\n",
    "combinedDf = pd.concat([bank_cust, clustersDf], axis = 1).reset_index()\n",
    "combinedDf = combinedDf.drop(['index', 'level_0'], axis = 1)\n",
    "cluster_0 = combinedDf[combinedDf['cluster_predicted'] == 0]\n",
    "cluster_1 = combinedDf[combinedDf['cluster_predicted'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d54deca",
   "metadata": {},
   "source": [
    "#### CLUSTERING MODELS : K MEANS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f794daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2,random_state=42)\n",
    "kmeans.fit(bank_cust)\n",
    "bank_cust['kmeans_cluster'] = kmeans.labels_\n",
    "plt.subplots(figsize=(15,5))\n",
    "sns.countplot(x=bank_cust['job'], order=bank_cust['job'].value_counts().index, hue=bank_cust['kmeans_cluster'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4846da1",
   "metadata": {},
   "source": [
    "#### CLUSTERING MODELS : HEIRARCHIAL CLUSTERING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea59486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "hierarchical = AgglomerativeClustering(n_clusters=2)\n",
    "bank_cust['hierarchical_cluster'] = hierarchical.fit_predict(bank_cust)\n",
    "plt.subplots(figsize=(15,5))\n",
    "sns.countplot(x=bank_cust['job'], order=bank_cust['job'].value_counts().index, hue=bank_cust['hierarchical_cluster'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load sample data\n",
    "data = datasets.load_iris()\n",
    "X = data.data\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define clustering techniques\n",
    "clustering_algorithms = {\n",
    "    'KMeans': KMeans(n_clusters=3),\n",
    "    'DBSCAN': DBSCAN(),\n",
    "    'Agglomerative': AgglomerativeClustering(n_clusters=3),\n",
    "    'GMM': GaussianMixture(n_components=3)\n",
    "}\n",
    "\n",
    "# Apply clustering techniques and evaluate\n",
    "results = {}\n",
    "for name, model in clustering_algorithms.items():\n",
    "    model.fit(X_scaled)\n",
    "    if hasattr(model, 'labels_'):\n",
    "        labels = model.labels_\n",
    "    else:\n",
    "        labels = model.predict(X_scaled)\n",
    "    silhouette = silhouette_score(X_scaled, labels)\n",
    "    results[name] = silhouette\n",
    "\n",
    "# Identify the best technique\n",
    "best_technique = max(results, key=results.get)\n",
    "print(f\"Best clustering technique: {best_technique} (Silhouette Score: {results[best_technique]:.2f})\")\n",
    "\n",
    "# Fine-tuning (if needed)\n",
    "# Example: tuning KMeans by trying different numbers of clusters\n",
    "for n_clusters in range(2, 6):\n",
    "    model = KMeans(n_clusters=n_clusters)\n",
    "    model.fit(X_scaled)\n",
    "    labels = model.labels_\n",
    "    silhouette = silhouette_score(X_scaled, labels)\n",
    "    print(f\"KMeans with {n_clusters} clusters - Silhouette Score: {silhouette:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4748ea",
   "metadata": {},
   "source": [
    "## METRICS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a697cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,accuracy_score,confusion_matrix,f1_score,classification_report\n",
    "\n",
    "\n",
    "\n",
    "MAE1=mean_absolute_error(y_test1, predictions1)\n",
    "MSE1=mean_squared_error(y_test1, predictions1)\n",
    "RMSE1=np.sqrt(metrics.mean_squared_error(y_test1, predictions1))\n",
    "r2_1 = r2_score(y_test1, predictions1)\n",
    "accuracy_score(y_test2, y_pred2)\n",
    "f1 = f1_score(Y_test, predictions)\n",
    "classification_report(y_test,predictions)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=['building_windows_float_processed', 'building_windows_non_float_processed', \n",
    "                         'vehicle_windows_float_processed', 'containers', 'tableware', 'headlamps'],\n",
    "            yticklabels=['building_windows_float_processed', 'building_windows_non_float_processed', \n",
    "                         'vehicle_windows_float_processed', 'containers', 'tableware', 'headlamps'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c5919",
   "metadata": {},
   "source": [
    "#### METRIC : ROC AUC CURVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ff9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_scores = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(Y_test, Y_scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54453ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2,\n",
    "         label='ROC curve (area = {0:0.2f})'\n",
    "         ''.format(roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic for multiclass (OvA)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce89e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Define feature variations\n",
    "feature_variations = [\"All Features\", \"Reduced Features pca\", \"Reduced Features tsne\"]\n",
    "\n",
    "# Plot ROC curves for each classifier and feature variation\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, (name, clf) in enumerate(classifiers.items(), 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    for feature_variation in feature_variations:\n",
    "        # Filter results for the current classifier and feature variation\n",
    "        results_subset = results_df[(results_df[\"Classifier\"] == name) & (results_df[\"Features\"] == feature_variation)]\n",
    "        precision = results_subset[\"Precision\"].values[0]\n",
    "        recall = results_subset[\"Recall\"].values[0]\n",
    "        f1 = results_subset[\"F1\"].values[0]\n",
    "        \n",
    "        # Fit the classifier\n",
    "        clf.fit(X_train, y_train_encoded)\n",
    "        \n",
    "        # Predict probabilities\n",
    "        y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Calculate ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_test_encoded, y_pred_proba)\n",
    "        \n",
    "        # Calculate ROC AUC\n",
    "        auc = roc_auc_score(y_test_encoded, y_pred_proba)\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plt.plot(fpr, tpr, label=f'{feature_variation} (AUC = {auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='grey')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {name}')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b315bfd",
   "metadata": {},
   "source": [
    "#### METRIC : PRECISION RECALL CURVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(Y_test, Y_scores)\n",
    "average_precision = average_precision_score(Y_test, Y_scores)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.step(recall, precision, color='b', where='post', label='Precision-Recall curve (AP = {:.2f})'.format(average_precision))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e16c39",
   "metadata": {},
   "source": [
    "## TABULATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d68766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_names = [\"Model 1\", \"Model 2\", \"Model 3\"]\n",
    "independent_variables = [\n",
    "   \"MAKE\",\"TRANSMISSION\",\"FUELTYPE\"\n",
    "]\n",
    "mse_values = [MSE1, MSE2, MSE3] \n",
    "mae_values = [MAE1, MAE2, MAE3]  \n",
    "rmse_values = [RMSE1, RMSE2, RMSE3]  \n",
    "r2_values = [r2_1, r2_2, r2_3]  \n",
    "\n",
    "\n",
    "data = {\n",
    "    \"S. No\": range(1, 4),\n",
    "    \"Regression Model Name\": model_names,\n",
    "    \"Independent Variables Chosen\": independent_variables,\n",
    "    \"MSE\": mse_values,\n",
    "    \"MAE\": mae_values,\n",
    "    \"RMSE\": rmse_values,\n",
    "    \"R-square\": r2_values\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(data)\n",
    "\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf6307",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [3, 5, 7, 9,12]\n",
    "models = []\n",
    "results = []\n",
    "\n",
    "for depth in depths:\n",
    "    model = DecisionTreeClassifier(criterion='entropy', max_depth=depth)\n",
    "    model.fit(x_train, y_train)\n",
    "    models.append(model)\n",
    "    \n",
    "for i, model in enumerate(models):\n",
    "    train_accuracy = model.score(x_train, y_train)\n",
    "    test_accuracy = model.score(x_test, y_test)\n",
    "    results.append({\n",
    "        'Depth': depths[i],\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Test Accuracy': test_accuracy\n",
    "    })\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0cec7",
   "metadata": {},
   "source": [
    "### PCA AND TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a4f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5544746",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=y)\n",
    "plt.title('PCA Visualization')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend(title='Attrition_Flag', loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# Visualize t-SNE\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_tsne[:,0], y=X_tsne[:,1], hue=y)\n",
    "plt.title('t-SNE Visualization')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.legend(title='Attrition_Flag', loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ead816",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
